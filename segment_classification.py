#! /usr/bin/python
version = "1.2.1"

# analysis of individual fibrils for identifying like crossovers and/or use in frealix.
# calculates crossover distance and statistics for each fibril
# classifies segments by x-over length independant of fibril
# input = .box files generated by e2boxer.py.  boxsize unimportant. runs on all box files in directory
# pick points in the same manner as would be done for frealix, have an extra endpoint picked at both the beginning and end of the fibril in addition to picked crossovers
# click off image so that either x or y coordinate is < 0 to start new fibril


## data restrictions
# current data limit 9,999 fibrils / 99,999 segments 
# NO dashes in filenames!!
# all images must be picked with same box size

## TODO/possible features:

# fix the problem where if the first picked point is too close to the edge the coordinates are negative becasue of the box size and the fibril is skipped. 

    

# v1.0.2 changed boxsize to 2x crossover length to make it similar to Saibil paper's method
# v1.0.3 changed it back to +20% of segemnt length
# v1.0.5 reorganized segemnt dicts, added per segment classes to fibril summaries, added output of FREALIX box files, added filesearch string
# v1.0.7 problems with particle coordinates bacause of differences between original and new boxsizes fixed
# v1.0.8 added search string for files to operate on rather than just all in directory
# v1.1.0 tested on real data worked, got decent class averages from extracted particles
# v1.2.0 added automatic claculation of the best number of classes
# v1.2.1 update extracton for relion 2.1

# 2014-11-13 MGI

print "\n*** 1-D Segment Classification v%s ***\n" % version
###----- variables ----###
filessearch = raw_input("files search string: ") or "img_*.box"
relscriptwrite = raw_input("write script for extraction for RELION? (y/n) ") or "y"

## imports
import numpy as np
import glob
import math
import os
import sys
from datetime import datetime
import matplotlib.pyplot as plt

########---------------------------- functions ------------------------------###

##----calculate distance----#
def calcdist(x2,x1,y2,y1):
    xdist = (x2-x1)**2
    ydist = (y2-y1)**2
    return math.sqrt(xdist + ydist)
##---------------------------#

##----Jenks Natural Breaks algorithm modified from Daniel J Lewis http://danieljlewis.org/----#
def jenks_matrices_init(data, n_classes):
    #fill the matrices with data+1 arrays of n_classes 0s
    lower_class_limits = []
    variance_combinations = []
    for i in xrange(0, len(data)+1):
        temp1 = []
        temp2 = []
        for j in xrange(0, n_classes+1):
            temp1.append(0.)
            temp2.append(0.)
        lower_class_limits.append(temp1)
        variance_combinations.append(temp2)
    inf = float('inf')
    for i in xrange(1, n_classes+1):
        lower_class_limits[1][i] = 1.
        variance_combinations[1][i] = 0.
        for j in xrange(2, len(data)+1):
            variance_combinations[j][i] = inf
    return lower_class_limits, variance_combinations
def jenks_matrices(data, n_classes):
    lower_class_limits, variance_combinations = jenks_matrices_init(data, n_classes)
    variance = 0.0
    for l in xrange(2, len(data)+1):
        sum = 0.0
        sum_squares = 0.0
        w = 0.0
        for m in xrange(1, l+1):
            # `III` originally
            lower_class_limit = l - m + 1
            val = data[lower_class_limit-1]
            # here we're estimating variance for each potential classing
            # of the data, for each potential number of classes. `w`
            # is the number of data points considered so far.
            w += 1
            # increase the current sum and sum-of-squares
            sum += val
            sum_squares += val * val
            # the variance at this point in the sequence is the difference
            # between the sum of squares and the total x 2, over the number
            # of samples.
            variance = sum_squares - (sum * sum) / w
            i4 = lower_class_limit - 1
            if i4 != 0:
                for j in xrange(2, n_classes+1):
                    if variance_combinations[l][j] >= (variance + variance_combinations[i4][j - 1]):
                        lower_class_limits[l][j] = lower_class_limit
                        variance_combinations[l][j] = variance + variance_combinations[i4][j - 1]
        lower_class_limits[l][1] = 1.
        variance_combinations[l][1] = variance
    return lower_class_limits, variance_combinations
def get_jenks_breaks(data, lower_class_limits, n_classes):
    k = len(data) - 1
    kclass = [0.] * (n_classes+1)
    countNum = n_classes
    kclass[n_classes] = data[len(data) - 1]
    kclass[0] = data[0]
    while countNum > 1:
        elt = int(lower_class_limits[k][countNum] - 2)
        kclass[countNum - 1] = data[elt]
        k = int(lower_class_limits[k][countNum] - 1)
        countNum -= 1
    return kclass
def jenks(data, n_classes):
    if n_classes > len(data): return
    data.sort()
    lower_class_limits, _ = jenks_matrices(data, n_classes)
    return get_jenks_breaks(data, lower_class_limits, n_classes)
##---------------------------#
####------------------------------------------------------------------------####

#------------goodness of varience fit -------------------------------------------------------------------
def goodness_of_var_fit(list,num_classes):
    mean_SDAM = sum(list)/len(list)
    Xdif2_SDAM = []
    for item in list:
        Xdif2_SDAM.append((item - mean_SDAM) ** 2)
    SDAM = sum(Xdif2_SDAM)
     
     
    #This is where break values are created
    break_list = jenks(list, num_classes)
     
    #This is where the class mean list is created
    class_mean_list = []
     
    temp_list = []
     
    for item in list:
        if item <= break_list[0]:
            temp_list.append(item)
    class_mean_list.append(sum(temp_list)/len(temp_list))
    del temp_list[:]
     
    for y in range(0, num_classes - 2):
        for item in list:
            if item > break_list[y] and item <= break_list[y+1]:
                temp_list.append(item)
        class_mean_list.append(sum(temp_list)/len(temp_list))
        del temp_list[:]
        y += 1
     
    for item in list:
        if item > break_list[num_classes - 2]:
            temp_list.append(item)
    class_mean_list.append(sum(temp_list)/len(temp_list))
    del temp_list[:]
     
    #This is where SDCM is calculated
    SDCM_list = []
     
    for item in list:
        if item <= break_list[0]:
            x_diff_2 = (item - class_mean_list[0]) ** 2
            SDCM_list.append(x_diff_2)
     
    for y in range(0, num_classes - 2):
        for item in list:
            if item > break_list[y] and item <= break_list[y+1]:
                x_diff_2 = (item - class_mean_list[y+1]) ** 2
                SDCM_list.append(x_diff_2)
        y += 1
     
    for item in list:
        if item > break_list[num_classes - 2]:
            x_diff_2 = (item - class_mean_list[num_classes - 1]) ** 2
            SDCM_list.append(x_diff_2)
     
    SDCM = sum(SDCM_list)
     
    #This is where the GVF value is calculated and displayed
    GVF = (SDAM - SDCM) / SDAM
     
    return(GVF,break_list)

######------------

### Program ###
# start the logfile
logout = open("seg-class.log","w")
logout.write("segment-classify.py v%s\t %s\n" % (version,datetime.now().strftime('%Y-%m-%d %H:%M:%S')))

# get the files to operate on
boxfiles = glob.glob(filessearch)
fibrildict = {}
if boxfiles == []:
   sys.exit( "** ERROR: no box files found **")


## read the files and get the info
indfibril = {}
filefilms = []
for i in boxfiles:
    coords = []
    filefilm = i.split('.')
    filename = filefilm[0]
    filefilms.append(filename)
    f = open(i)
    data = f.readlines()
    f.close()
    for j in data:
        coords.append((float(j.split('\t')[0]),float(j.split('\t')[1])))
    oboxsize = float(j.split('\t')[2])

## split the data into individual fibrils
    indfibno = 1
    
    for point in coords:
        if "%s-%.4d" % (filename,indfibno) not in indfibril.keys():
            indfibril["%s-%.4d" % (filename,indfibno)] = [[],float(j.split('\t')[2])]
        if point[0] >= 0:
            indfibril["%s-%.4d" % (filename,indfibno)][0].append(point)
        else:
            indfibno = indfibno+1

#assign each segment to a fibril and put them in a dict

allsegsdic = {}
logout.write("\n ** All fibrils ****************************************\n")
allfiblengths = []
for i in indfibril:
    
    segments = []
    segdic = {}
    for k in range(1,len(indfibril[i][0])-2):
        distance = calcdist(indfibril[i][0][k+1][0],indfibril[i][0][k][0],indfibril[i][0][k+1][1],indfibril[i][0][k][1])
        segments.append(distance)
        segdic[k] = distance
        allsegsdic["%s-%.5d" % (i,k)] = (distance, indfibril[i][0][k],indfibril[i][0][k+1])
    mean = np.mean(segments)
    sd = np.std(segments)
    fiblength = sum(segments)
    allfiblengths.append(fiblength)
    logout.write("%s\t%s\n" % (i,indfibril[i]))


# output all of the info about the data and write the logfile
print "\n** fibrils stats ****************************************"
print "count\tmin\tmax\tmean\tstd"
print "%s\t%.2f\t%.2f\t%.2f\t%.2f" % (len(allfiblengths),min(allfiblengths),max(allfiblengths),np.mean(allfiblengths),np.std(allfiblengths))  
logout.write("\n** All segments **\n")
allsegslengths = []
for i in allsegsdic:
    logout.write("%s\t%s\n" % (i,allsegsdic[i]))
    allsegslengths.append(allsegsdic[i][0])


# calc all segments statistics:
print "\n** segments stats ****************************************"
print "count\tmin\tmax\tmean\tstd"
print "%s\t%.2f\t%.2f\t%.2f\t%.2f" % (len(allsegslengths),min(allsegslengths),max(allsegslengths),np.mean(allsegslengths),np.std(allsegslengths))
logout.write("\n** fibrils stats **\n")
logout.write("count\tmin\tmax\tmean\tstd\n")
logout.write("%s\t%.2f\t%.2f\t%.2f\t%.2f\n" % (len(allfiblengths),min(allfiblengths),max(allfiblengths),np.mean(allfiblengths),np.std(allfiblengths)))
logout.write("\n** segments stats **\n")
logout.write("count\tmin\tmax\tmean\tstd\n")
logout.write("%s\t%.2f\t%.2f\t%.2f\t%.2f\n" % (len(allsegslengths),min(allsegslengths),max(allsegslengths),np.mean(allsegslengths),np.std(allsegslengths)))

## make segments distribution graph
plt.hist(allsegslengths)
plt.xlabel('crossover length')
plt.ylabel('# fibrils')
plt.savefig('fibrils_histogram.png')
plt.close()


# find the right number of classes fvor the dataset
gvfthresh = 0.8
gvf= 0.0
print "\n** Finding the right number of classes **************************************** \noptimum number of breaks by goodness of varience fit 1st past {0}\n# classes\tgoodness of varience fit".format(gvfthresh)
nclasses = 3
while gvf < gvfthresh:
    if nclasses <= 0.75 * len(allsegslengths):
        result = goodness_of_var_fit(allsegslengths,nclasses-1)
        print'{0}\t\t{1}'.format(nclasses,result[0])
        gvf = result[0]
        nclasses += 1
    else:
        gvf = 0.9

print("using {0} classes".format(nclasses-1))
jenksclasses = nclasses-1
breaks = result[1]
print("class breaks: {0}".format(breaks))
logout.write("classes: %s\n" % (jenksclasses))



## classification

classbreaks = jenks(allsegslengths, jenksclasses)[1:]
classesdic = {}
for k in range(0,len(classbreaks)):
    classesdic[k] = []
csegsdic = {}
for j in allsegsdic:
    classesdic[min(enumerate(classbreaks), key=lambda x: abs(x[1]-allsegsdic[j][0]))[0]].append(allsegsdic[j][0])
    csegsdic[j] = ((min(enumerate(classbreaks), key=lambda x: abs(x[1]-allsegsdic[j][0]))[0]),allsegsdic[j][0],allsegsdic[j][1],allsegsdic[j][2],j.split("-")[0],j.split("-")[1],j.split("-")[2])
# calculate boxsize for each class

fibimgsort = sorted(csegsdic.items(), key=lambda x: x[0])

#print "\n** individual fibrils **"
#print "image\tfibil\tsegment\tlength\tclass"

startimg = ""
startno = ""
for i in fibimgsort:
    if i[1][4] != startimg or i[1][5] != startno :
        logout.write("\n%s\n\t%s\t%s\t%s\t%s" % (i[1][4],int(i[1][5]),int(i[1][6]),round(i[1][1], 1),i[1][0]))
    else:
        logout.write("\n\t%s\t%s\t%s\t%s" % (int(i[1][5]),int(i[1][6]),round(i[1][1], 1),i[1][0]))
    startimg = i[1][4]
    startno = i[1][5]

# evaluate the fibrils to find ones where a high % of segments are in the same class

# calculate curvature for each fibril:
for i in indfibril:
    seglengths = []
    for j in range(1,len(indfibril[i][0])-2):
        seglengths.append(calcdist(indfibril[i][0][j][0],indfibril[i][0][j+1][0],indfibril[i][0][j][1],indfibril[i][0][j+1][1]))
    totaldist = calcdist(indfibril[i][0][1][0],indfibril[i][0][len(indfibril[i][0])-2][0],indfibril[i][0][1][1],indfibril[i][0][len(indfibril[i][0])-2][1])
    indfibril[i].append([totaldist,sum(seglengths)])

# calculate class distribution for each fibril
fibsegscores = {}
for i in  csegsdic:
    if "%s-%s" % (csegsdic[i][4],csegsdic[i][5]) not in fibsegscores.keys():
        fibsegscores["%s-%s" % (csegsdic[i][4],csegsdic[i][5])] = [csegsdic[i][0]]
    else:
        fibsegscores["%s-%s" % (csegsdic[i][4],csegsdic[i][5])].append(csegsdic[i][0])

print "\n** Fibrils evaluation ****************************************"
print "fibril\t\t# segments\tmeanclassdist\tcurvaturescore "
for i in fibsegscores:
    runningscore = []
    for j in fibsegscores[i]:
        for k in fibsegscores[i]:
            runningscore.append(abs(j-k))
    if len(runningscore)-len(fibsegscores[i]) > 0:
        print "%s\t%s\t\t%0.3f\t\t%0.2f" % (i,len(fibsegscores[i]),(float(sum(runningscore))/(len(runningscore)-len(fibsegscores[i]))),abs(indfibril[i][2][1]-indfibril[i][2][0]))
    else:
        print "%s\t%s\t\t%s\t\t%s" % (i,len(fibsegscores[i]),"XX","XX")

# box size calculations for each class

boxsizedic = {}
for j in classesdic:
    segsizes = []
    for k in csegsdic:
        if csegsdic[k][0] == j:
            segsizes.append(csegsdic[k][1])
            boxsizedic[j] = [int(round(1.3*(max(segsizes)),-1))]                  # determination of box size
print('\n** Segment classification ****************************************')
print "%s classes" % jenksclasses
logout.write("\n** %s classes **\n" % jenksclasses)
print "class\tcount\tmean\tstd\trange\tboxsize"
logout.write("class\tcount\tmean\tstd\trange\tboxsize\n")
for m in classesdic:
    print "%s\t%s\t%.2f\t%.2f\t%.2f\t%s" % (m, len(classesdic[m]),np.mean(classesdic[m]),np.std(classesdic[m]),max(classesdic[m])-min(classesdic[m]),boxsizedic[m][0])
    logout.write("%s\t%s\t%.2f\t%.2f\t%.2f\t%s\n" % (m, len(classesdic[m]),np.mean(classesdic[m]),np.std(classesdic[m]),max(classesdic[m])-min(classesdic[m]),boxsizedic[m][0]))


# calculate the box coordinates for each segment

boxdatadic = {}
for i in filefilms:
    for k in boxsizedic:
        filename = "%s_class%.3d.box" % (i,k)
        boxdatadic[filename] = []
        for j in csegsdic:
            if j.split("-")[0] == i and csegsdic[j][0] == k:
                boxdiff = boxsizedic[k][0] - oboxsize
                xcent = ((csegsdic[j][2][0]+csegsdic[j][3][0])/2)-(0.5*boxdiff)
                ycent = ((csegsdic[j][2][1]+csegsdic[j][3][1])/2)-(0.5*boxdiff)
                boxdatadic[filename].append((xcent,ycent,boxsizedic[k][0],boxsizedic[k][0]))


# write the script to run relion - need to fix for latest version of relion - now updated to relion 2.1
if relscriptwrite == "y":
    relscript = open("seg-analysis-relion.sh","w")
    relscript.write('if [ -z "$1" ]; then\n\techo "USAGE: seg-analysis-relion.sh <micrograph star file name>"\n\texit\nfi\n')
    for i in boxsizedic:
            
        relscript.write("mpirun -n 16 `which relion_preprocess_mpi` --i $1 --coord_dir boxfiles --coord_suffix _class%.3d.box --part_star Particles/class%.3d/class%.3d.star --part_dir Particles/class%.3d/ --extract --extract_size %s --norm --bg_radius %.0f --white_dust 5 --black_dust 5 \n" % (i,i,i,i,boxsizedic[i][0],0.45*boxsizedic[i][0]))
    print "\nwrote seg-analysis-relion.sh"

## make the box files for RELION one for each class in each image
    if os.path.isdir('boxfiles') != True:
        os.system('mkdir boxfiles')
    bfcount = 0
    logout.write("boxfiles written:\n")
    for i in boxdatadic:
        if boxdatadic[i] != []:
            logout.write("%s\n" % i)
            output = open('boxfiles/{0}'.format(i.split('/')[-1]),"w")
            for j in boxdatadic[i]:
                output.write("%.0f\t%.0f\t%.0f\t%.0f\n" % (j[0],j[1],j[2],j[3]))
            output.close()
            bfcount = bfcount+1
    print "\n%s boxfiles written for RELION/EMAN" % bfcount
